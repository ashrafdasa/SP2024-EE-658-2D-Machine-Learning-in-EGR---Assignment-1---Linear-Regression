{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ashraf Dasa (AYDASA@UAB.EDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification,fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "#Load the MNIST dataset. \n",
    "mnist = fetch_openml('mnist_784', version=1) \n",
    "print(type(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197414</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.991206</td>\n",
       "      <td>4.256304</td>\n",
       "      <td>2.783732</td>\n",
       "      <td>1.561822</td>\n",
       "      <td>1.553796</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7   pixel8  \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel9  pixel10  ...      pixel775      pixel776      pixel777  \\\n",
       "count  70000.0  70000.0  ...  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.0      0.0  ...      0.197414      0.099543      0.046629   \n",
       "std        0.0      0.0  ...      5.991206      4.256304      2.783732   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "           pixel778      pixel779      pixel780  pixel781  pixel782  pixel783  \\\n",
       "count  70000.000000  70000.000000  70000.000000   70000.0   70000.0   70000.0   \n",
       "mean       0.016614      0.012957      0.001714       0.0       0.0       0.0   \n",
       "std        1.561822      1.553796      0.320889       0.0       0.0       0.0   \n",
       "min        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "25%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "50%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "75%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "max      253.000000    254.000000     62.000000       0.0       0.0       0.0   \n",
       "\n",
       "       pixel784  \n",
       "count   70000.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = mnist['frame'] \n",
    "print(data_df.shape)\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  class  \n",
       "0       0.0       0.0       0.0      5  \n",
       "1       0.0       0.0       0.0      0  \n",
       "2       0.0       0.0       0.0      4  \n",
       "3       0.0       0.0       0.0      1  \n",
       "4       0.0       0.0       0.0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "           ..\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "class       0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of nuls per each column\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out the features in an array and take out the lables in another array\n",
    "features_raw = data_df[data_df.columns[:-1]].values\n",
    "lables = data_df[data_df.columns[-1]].values\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max values in features before scaling :  255.0\n",
      "the min values in features before scaling :  0.0\n"
     ]
    }
   ],
   "source": [
    "# normalizing features \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(features_raw) \n",
    "print(\"the max values in features before scaling : \",features_raw.max().max()) \n",
    "print(\"the min values in features before scaling : \",features_raw.min().min()) \n",
    "features = scaler.transform(features_raw) # transform the features to StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (56000, 784)\n",
      "X_test:  (14000, 784)\n",
      "y_train:  (56000,)\n",
      "y_test:  (14000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=0.2, random_state=42) \n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape) \n",
    "print(\"y_test: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset originally had 784 features (columns). We aimed to reduce this number using Principal Component Analysis (PCA) while retaining most of the information. We started by keeping the top 50 principal components, which captured 43% of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000, 50)\n",
      "(14000, 784) (14000, 50)\n",
      "0.4373978939213167\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "print(X_train.shape, X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_test.shape, X_test_pca.shape)\n",
    "\n",
    "print(pca.noise_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Explore the variance explained by the selected number\n",
    "#  of components and adjust if necessary to retain at least\n",
    "# 95% of the variance.\n",
    "n_componentsExplore = []\n",
    "for n_components in range(5,784,25): \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    noise_variance = pca.noise_variance_\n",
    "    n_componentsExplore.append([n_components,noise_variance]) \n",
    "    if(noise_variance < 0.05):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 0.7461170433292454],\n",
       " [30, 0.5208512615736208],\n",
       " [55, 0.4206365826195105],\n",
       " [80, 0.35148862085679317],\n",
       " [105, 0.29616477290608867],\n",
       " [130, 0.2518414187031177],\n",
       " [155, 0.21298846723225007],\n",
       " [180, 0.1804277796982072],\n",
       " [205, 0.15407449695463218],\n",
       " [230, 0.13215853799050223],\n",
       " [255, 0.11467577530595356],\n",
       " [280, 0.10024391623636372],\n",
       " [305, 0.08809805927432372],\n",
       " [330, 0.07777820168987501],\n",
       " [355, 0.06912136440487493],\n",
       " [380, 0.06167311242764846],\n",
       " [405, 0.055253201130123566],\n",
       " [430, 0.04947378672653263]]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_componentsExplore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal number of components for our analysis, the below loop that iteratively increased the number of components by 25, all the way up to 784. The loop stopped when the explained variance reached 95%. This process is visualized in a scree plot, which helps us see how adding more components contributes to the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scree plot to find the elbo at 0.05\n",
    "n_componentsExploreArr = np.zeros([len(n_componentsExplore),2])\n",
    "for i in n_componentsExplore: \n",
    "    n_componentsExploreArr = np.append(n_componentsExploreArr,[i] , axis=0)\n",
    "    \n",
    "plt.style.use('_mpl-gallery') \n",
    "x = np.matrix(n_componentsExplore)[:,0]\n",
    "y = np.matrix(n_componentsExplore)[:,1] \n",
    "fig, ax = plt.subplots()\n",
    "plt.axhline(y = 0.05, color = 'r', linestyle = 'dashed')    \n",
    "ax.plot(x, y, linewidth=2.0) \n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an alternative method provided by scikit-learn. This method allows us to specify the desired explained variance, and scikit-learn will find the closest number of components that achieves that level of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07801665582474857\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "# alternative method: \n",
    "pca = PCA(n_components= 0.95, svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "print(pca.noise_variance_)\n",
    "print(len(pca.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000, 400)\n",
      "(14000, 784) (14000, 400)\n",
      "0.05645825103308629\n"
     ]
    }
   ],
   "source": [
    "# For this particular task, I chose to use 400 components \n",
    "n_components = 400\n",
    "pca = PCA(n_components= n_components)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# transforming x train and x test\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_train_pca.shape)\n",
    "print(X_test.shape, X_test_pca.shape)\n",
    "print(pca.noise_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultsSummary = pd.DataFrame([])\n",
    "def calculateAcc(y_test,y_predict,methodName1,methodNam2,executionTime,df_resultsSummary, printResults = True): \n",
    "    conf_matrix = confusion_matrix(y_test, y_predict ) \n",
    "    if(printResults):\n",
    "        print(conf_matrix) \n",
    "        print(classification_report(y_test, y_predict ))\n",
    "    acc_ovr = accuracy_score(y_test, y_predict)\n",
    "    return pd.concat([df_resultsSummary,pd.DataFrame([[methodName1,methodNam2,acc_ovr,executionTime]]\n",
    "                                                     ,columns=[\"Model\",\"Data\",\"accuracy\",\"executionTime\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1305    1    5    0    1    6   14    2    8    1]\n",
      " [   0 1557    5    8    2   10    1    3   13    1]\n",
      " [   8   16 1233   23   16   13   18   15   31    7]\n",
      " [   7   11   34 1269    1   38    7   18   25   23]\n",
      " [   4    2    9    6 1200    3    7    7   13   44]\n",
      " [   8   10    7   50   14 1112   21    7   34   10]\n",
      " [   4    5   16    1   11   23 1330    0    6    0]\n",
      " [   6    4   21    3   14    7    0 1409    5   34]\n",
      " [  14   37   17   44    9   45   14   10 1138   29]\n",
      " [   8    9    6   23   46    9    0   52   11 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1343\n",
      "           1       0.94      0.97      0.96      1600\n",
      "           2       0.91      0.89      0.90      1380\n",
      "           3       0.89      0.89      0.89      1433\n",
      "           4       0.91      0.93      0.92      1295\n",
      "           5       0.88      0.87      0.88      1273\n",
      "           6       0.94      0.95      0.95      1396\n",
      "           7       0.93      0.94      0.93      1503\n",
      "           8       0.89      0.84      0.86      1357\n",
      "           9       0.89      0.88      0.89      1420\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement a Logistic Regression classifier.\n",
    "ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "# Train One-Vs-Rest Logistic Regression\n",
    "startTime = time.time()\n",
    "ovr.fit(X_train, y_train)\n",
    "executionTime = time.time()-startTime\n",
    "# predict lbfgs PCA\n",
    "y_predict =ovr.predict(X_test)  \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"Logistic Regression\",\n",
    "                                 \"all Features - no PCA\", executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1304    1    4    1    2    8   11    2    8    2]\n",
      " [   0 1557    4    9    2    9    3    4   11    1]\n",
      " [   6   18 1239   17   15   10   19   15   34    7]\n",
      " [   8    9   37 1268    2   41    6   19   25   18]\n",
      " [   3    2    8    7 1201    3    6    8   12   45]\n",
      " [   7    8    6   50   16 1113   23    5   35   10]\n",
      " [   6    4   16    1   10   19 1335    0    5    0]\n",
      " [   5    4   21    0   11    7    0 1421    2   32]\n",
      " [  10   36   15   40    9   44   12   12 1154   25]\n",
      " [  10   10    6   22   45    9    0   52   13 1253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1343\n",
      "           1       0.94      0.97      0.96      1600\n",
      "           2       0.91      0.90      0.91      1380\n",
      "           3       0.90      0.88      0.89      1433\n",
      "           4       0.91      0.93      0.92      1295\n",
      "           5       0.88      0.87      0.88      1273\n",
      "           6       0.94      0.96      0.95      1396\n",
      "           7       0.92      0.95      0.93      1503\n",
      "           8       0.89      0.85      0.87      1357\n",
      "           9       0.90      0.88      0.89      1420\n",
      "\n",
      "    accuracy                           0.92     14000\n",
      "   macro avg       0.92      0.92      0.92     14000\n",
      "weighted avg       0.92      0.92      0.92     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "# Train One-Vs-Rest Logistic Regression\n",
    "startTime = time.time()\n",
    "ovr.fit(X_train_pca, y_train)\n",
    "executionTime = time.time()-startTime\n",
    "# predict lbfgs PCA\n",
    "y_predict =ovr.predict(X_test_pca)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"Logistic Regression\",\n",
    "                                 \"PCA (400 components)\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1252    0   11    1    9   19   29    2   11    9]\n",
      " [   0 1531   11   12    1    8    1    7   28    1]\n",
      " [  27   28 1224   34   10    3   15   13   23    3]\n",
      " [   7   14   30 1268    2   46    3   25   18   20]\n",
      " [   8    1    9    0 1183    7   22   14   11   40]\n",
      " [   6    7    8   54    7 1096   10   10   52   23]\n",
      " [  16    4   20    0   22   15 1302    3   13    1]\n",
      " [   3   12   17   23   18   17    2 1348    2   61]\n",
      " [  13   24   33   28    4   61   16    8 1144   26]\n",
      " [  13    2    3   10   62   16    3   61   13 1237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1343\n",
      "           1       0.94      0.96      0.95      1600\n",
      "           2       0.90      0.89      0.89      1380\n",
      "           3       0.89      0.88      0.89      1433\n",
      "           4       0.90      0.91      0.91      1295\n",
      "           5       0.85      0.86      0.86      1273\n",
      "           6       0.93      0.93      0.93      1396\n",
      "           7       0.90      0.90      0.90      1503\n",
      "           8       0.87      0.84      0.86      1357\n",
      "           9       0.87      0.87      0.87      1420\n",
      "\n",
      "    accuracy                           0.90     14000\n",
      "   macro avg       0.90      0.90      0.90     14000\n",
      "weighted avg       0.90      0.90      0.90     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part IV: Neural Network Classifier \n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "startTime = time.time()\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "executionTime = time.time()-startTime \n",
    "y_predict =mlp_clf.predict(X_test)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"NN Classifier, 3 layers, logistic\",\n",
    "                                \"All Features - no PCA\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1252    2   15    1    0   29   32    3    9    0]\n",
      " [   1 1548    8   10    2    3    1   10   13    4]\n",
      " [  27   14 1229   25   10    9   12   17   31    6]\n",
      " [   0    5   31 1275    2   57    0   23   26   14]\n",
      " [   2    5    3    1 1186   11   20    6    7   54]\n",
      " [   8    4    3   59    7 1122   12    6   43    9]\n",
      " [  31    3   13    0   22   14 1304    0    7    2]\n",
      " [   8   12   11   31    7    8    1 1376    2   47]\n",
      " [   8   21   18   28    6   34   20    5 1201   16]\n",
      " [   4    4    6   12   55   16    3   34   11 1275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1343\n",
      "           1       0.96      0.97      0.96      1600\n",
      "           2       0.92      0.89      0.90      1380\n",
      "           3       0.88      0.89      0.89      1433\n",
      "           4       0.91      0.92      0.92      1295\n",
      "           5       0.86      0.88      0.87      1273\n",
      "           6       0.93      0.93      0.93      1396\n",
      "           7       0.93      0.92      0.92      1503\n",
      "           8       0.89      0.89      0.89      1357\n",
      "           9       0.89      0.90      0.90      1420\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "startTime = time.time()\n",
    "mlp_clf.fit(X_train_pca, y_train)\n",
    "executionTime = time.time()-startTime \n",
    "y_predict = mlp_clf.predict(X_test_pca)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"NN Classifier, 3 layers, logistic\",\n",
    "                                 \"PCA (400 components)\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Options [['adam', 'logistic', 'constant', 'All Features - no PCA'], ['adam', 'logistic', 'constant', 'PCA (400 components)'], ['adam', 'logistic', 'adaptive', 'All Features - no PCA'], ['adam', 'logistic', 'adaptive', 'PCA (400 components)'], ['adam', 'relu', 'constant', 'All Features - no PCA'], ['adam', 'relu', 'constant', 'PCA (400 components)'], ['adam', 'relu', 'adaptive', 'All Features - no PCA'], ['adam', 'relu', 'adaptive', 'PCA (400 components)'], ['adam', 'tanh', 'constant', 'All Features - no PCA'], ['adam', 'tanh', 'constant', 'PCA (400 components)'], ['adam', 'tanh', 'adaptive', 'All Features - no PCA'], ['adam', 'tanh', 'adaptive', 'PCA (400 components)'], ['sgd', 'logistic', 'constant', 'All Features - no PCA'], ['sgd', 'logistic', 'constant', 'PCA (400 components)'], ['sgd', 'logistic', 'adaptive', 'All Features - no PCA'], ['sgd', 'logistic', 'adaptive', 'PCA (400 components)'], ['sgd', 'relu', 'constant', 'All Features - no PCA'], ['sgd', 'relu', 'constant', 'PCA (400 components)'], ['sgd', 'relu', 'adaptive', 'All Features - no PCA'], ['sgd', 'relu', 'adaptive', 'PCA (400 components)'], ['sgd', 'tanh', 'constant', 'All Features - no PCA'], ['sgd', 'tanh', 'constant', 'PCA (400 components)'], ['sgd', 'tanh', 'adaptive', 'All Features - no PCA'], ['sgd', 'tanh', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'logistic', 'constant', 'All Features - no PCA'], ['lbfgs', 'logistic', 'constant', 'PCA (400 components)'], ['lbfgs', 'logistic', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'logistic', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'relu', 'constant', 'All Features - no PCA'], ['lbfgs', 'relu', 'constant', 'PCA (400 components)'], ['lbfgs', 'relu', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'relu', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'tanh', 'constant', 'All Features - no PCA'], ['lbfgs', 'tanh', 'constant', 'PCA (400 components)'], ['lbfgs', 'tanh', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'tanh', 'adaptive', 'PCA (400 components)']]\n",
      "['sgd', 'tanh', 'adaptive', 'All Features - no PCA']\n",
      "['sgd', 'relu', 'constant', 'PCA (400 components)']\n",
      "['sgd', 'tanh', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'logistic', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'relu', 'adaptive', 'PCA (400 components)']\n",
      "['adam', 'relu', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'logistic', 'constant', 'All Features - no PCA']\n",
      "['adam', 'relu', 'adaptive', 'PCA (400 components)']\n",
      "['adam', 'tanh', 'constant', 'All Features - no PCA']\n",
      "['sgd', 'tanh', 'constant', 'All Features - no PCA']\n"
     ]
    }
   ],
   "source": [
    "# Define the grid search space\n",
    "optimizers = ['adam', 'sgd','lbfgs']\n",
    "activations = ['logistic','relu', 'tanh']  \n",
    "learning_rate = ['constant', 'adaptive']\n",
    "dataSource = ['All Features - no PCA','PCA (400 components)']\n",
    "\n",
    "options = [] # define empty list \n",
    "for optimizer, activation,learning_rate,dataSource in product(optimizers, activations,learning_rate,dataSource):\n",
    "  options.append([optimizer,activation,learning_rate,dataSource]) # add all possible options \n",
    "\n",
    "searchingOptions = np.random.choice(len(options),10, replace=False) # randomly pick 10 options \n",
    "print(\"All Options\", options) \n",
    "for i in searchingOptions:\n",
    "  print(options[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sgd', 'tanh', 'adaptive', 'All Features - no PCA']  accuracy: 0.9167857142857143\n",
      "['sgd', 'relu', 'constant', 'PCA (400 components)']  accuracy: 0.9393571428571429\n",
      "['sgd', 'tanh', 'constant', 'PCA (400 components)']  accuracy: 0.927\n",
      "['lbfgs', 'logistic', 'constant', 'PCA (400 components)']  accuracy: 0.9050714285714285\n",
      "['lbfgs', 'relu', 'adaptive', 'PCA (400 components)']  accuracy: 0.9363571428571429\n",
      "['adam', 'relu', 'constant', 'PCA (400 components)']  accuracy: 0.9352857142857143\n",
      "['lbfgs', 'logistic', 'constant', 'All Features - no PCA']  accuracy: 0.9005\n",
      "['adam', 'relu', 'adaptive', 'PCA (400 components)']  accuracy: 0.9388571428571428\n",
      "['adam', 'tanh', 'constant', 'All Features - no PCA']  accuracy: 0.9128571428571428\n",
      "['sgd', 'tanh', 'constant', 'All Features - no PCA']  accuracy: 0.9152142857142858\n"
     ]
    }
   ],
   "source": [
    "for i in searchingOptions: \n",
    "    activation = options[i][1] \n",
    "    solver = options[i][0] \n",
    "    learning_rate = options[i][2]\n",
    "    dataSource = options[i][3] \n",
    "    if(dataSource == \"All Features - no PCA\"):\n",
    "        trainingData = X_train\n",
    "        testingData = X_test\n",
    "    else:\n",
    "        trainingData = X_train_pca\n",
    "        testingData = X_test_pca\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 500,\n",
    "                             activation = activation, solver = solver,learning_rate=learning_rate)\n",
    "    startTime = time.time()\n",
    "    mlp_clf.fit(trainingData, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict = mlp_clf.predict(testingData)   \n",
    "    df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                    \"hyperparameters activation\" + activation + \" solver:\" + solver + \" learning_rate\" + learning_rate,\n",
    "                                    dataSource,\n",
    "                                    executionTime,\n",
    "                                    df_resultsSummary,printResults=False)\n",
    "    print(options[i],\" accuracy:\",df_resultsSummary.tail(1)[\"accuracy\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>executionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>25.284516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN Classifier, 3 layers, logistic</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.898929</td>\n",
       "      <td>317.773614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN Classifier, 3 layers, logistic</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>185.229174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.916786</td>\n",
       "      <td>357.610471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:sgd lear...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.939357</td>\n",
       "      <td>228.033520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>216.902335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationlogistic solver:lbfg...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>120.471338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:lbfgs le...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.936357</td>\n",
       "      <td>79.072497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:adam lea...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.935286</td>\n",
       "      <td>109.893801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationlogistic solver:lbfg...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.900500</td>\n",
       "      <td>192.081178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:adam lea...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.938857</td>\n",
       "      <td>116.923919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:adam lea...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>133.931399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.915214</td>\n",
       "      <td>438.949612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model                   Data  \\\n",
       "0                                Logistic Regression   PCA (400 components)   \n",
       "0                  NN Classifier, 3 layers, logistic  All Features - no PCA   \n",
       "0                  NN Classifier, 3 layers, logistic   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:sgd lear...  All Features - no PCA   \n",
       "0  hyperparameters activationrelu solver:sgd lear...   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:sgd lear...   PCA (400 components)   \n",
       "0  hyperparameters activationlogistic solver:lbfg...   PCA (400 components)   \n",
       "0  hyperparameters activationrelu solver:lbfgs le...   PCA (400 components)   \n",
       "0  hyperparameters activationrelu solver:adam lea...   PCA (400 components)   \n",
       "0  hyperparameters activationlogistic solver:lbfg...  All Features - no PCA   \n",
       "0  hyperparameters activationrelu solver:adam lea...   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:adam lea...  All Features - no PCA   \n",
       "0  hyperparameters activationtanh solver:sgd lear...  All Features - no PCA   \n",
       "\n",
       "   accuracy  executionTime  \n",
       "0  0.917500      25.284516  \n",
       "0  0.898929     317.773614  \n",
       "0  0.912000     185.229174  \n",
       "0  0.916786     357.610471  \n",
       "0  0.939357     228.033520  \n",
       "0  0.927000     216.902335  \n",
       "0  0.905071     120.471338  \n",
       "0  0.936357      79.072497  \n",
       "0  0.935286     109.893801  \n",
       "0  0.900500     192.081178  \n",
       "0  0.938857     116.923919  \n",
       "0  0.912857     133.931399  \n",
       "0  0.915214     438.949612  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultsSummary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
