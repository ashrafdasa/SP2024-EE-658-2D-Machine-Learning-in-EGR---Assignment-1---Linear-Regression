{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ashraf Dasa (AYDASA@UAB.EDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'streamlit' from 'C:\\\\Users\\\\xu7719\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\streamlit\\\\__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification,fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import product\n",
    "import warnings\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultsSummary = pd.DataFrame([])\n",
    "def calculateAcc(y_test,y_predict,dataSetName,alg,info,numberOfParameters,executionTime): \n",
    "    #conf_matrix = confusion_matrix(y_test, y_predict )  \n",
    "    acc  = accuracy_score(y_test, y_predict) \n",
    "    result = {\"dataSetName\": dataSetName,\n",
    "              \"alg\":alg,\n",
    "              \"Training Time (s)\":round(executionTime,2),\n",
    "              \"modelAccurecy (%)\": round(100 * acc), \n",
    "              \"info\":info} \n",
    "    with open(\"./models/\"+dataSetName +\"_\"+ alg+\".json\", \"w\") as outfile: \n",
    "        json.dump(result, outfile)\n",
    "    \n",
    "    print(dataSetName, alg, acc)\n",
    "     \n",
    "    return; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelingPipeline(dataSetName,X_train,y_train,X_test,y_test):\n",
    "    # LogisticRegression\n",
    "    alg = \"Logistic Regression\" \n",
    "    ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "    startTime = time.time()\n",
    "    ovr.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime\n",
    "    y_predict =ovr.predict(X_test) \n",
    "    info = {\"solver\":\"lbfgs\"}\n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "    \n",
    "    # Neural Network Classifier \n",
    "    alg = \"Neural Network Classifier\" \n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "    startTime = time.time()\n",
    "    mlp_clf.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =mlp_clf.predict(X_test)   \n",
    "    info = { \"activation\" : 'logistic', \"solver\" : 'adam'}\n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "    \n",
    "\n",
    "    # Gaussian Naive Bayes\n",
    "    alg = \"Naive Bayes\"\n",
    "    gnb = GaussianNB()\n",
    "    startTime = time.time()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =gnb.predict(X_test) \n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "\n",
    "    # Decision Tree\n",
    "    alg = \"Decision Tree\"\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    startTime = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =clf.predict(X_test) \n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Logistic Regression 0.9666666666666667\n",
      "IRIS Neural Network Classifier 0.9666666666666667\n",
      "IRIS Naive Bayes 1.0\n",
      "IRIS Decision Tree 1.0\n"
     ]
    }
   ],
   "source": [
    "dataSetName = \"IRIS\"\n",
    "iris = datasets.load_iris()  \n",
    "X = iris.data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X)  \n",
    "pickle.dump(scaler, open( \"models/scaling_\" + dataSetName + \".pkl\" , 'wb'))\n",
    "X = scaler.transform(X)\n",
    "y = iris.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "modelingPipeline( dataSetName, X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits Logistic Regression 0.9666666666666667\n",
      "Digits Neural Network Classifier 0.9111111111111111\n",
      "Digits Naive Bayes 0.7666666666666667\n",
      "Digits Decision Tree 0.8638888888888889\n"
     ]
    }
   ],
   "source": [
    "dataSetName = \"Digits\"\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X)   \n",
    "pickle.dump(scaler, open( \"models/scaling_\" + dataSetName + \".pkl\" , 'wb'))\n",
    "X = scaler.transform(X)\n",
    "y = digits.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "modelingPipeline( dataSetName, X_train,y_train,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
