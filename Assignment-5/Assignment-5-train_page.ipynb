{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ashraf Dasa (AYDASA@UAB.EDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'streamlit' from 'C:\\\\Users\\\\xu7719\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\streamlit\\\\__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification,fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import product\n",
    "import warnings\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultsSummary = pd.DataFrame([])\n",
    "def calculateAcc(y_test,y_predict,dataSetName,alg,info,numberOfParameters,executionTime): \n",
    "    #conf_matrix = confusion_matrix(y_test, y_predict )  \n",
    "    acc  = accuracy_score(y_test, y_predict) \n",
    "    result = {\"dataSetName\": dataSetName,\n",
    "              \"alg\":alg,\n",
    "              \"Training Time (s)\":round(executionTime,2),\n",
    "              \"modelAccurecy (%)\": round(100 * acc), \n",
    "              \"info\":info} \n",
    "    with open(\"./models/\"+dataSetName +\"_\"+ alg+\".json\", \"w\") as outfile: \n",
    "        json.dump(result, outfile)\n",
    "    \n",
    "    print(dataSetName, alg, acc)\n",
    "     \n",
    "    return; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelingPipeline(dataSetName,X_train,y_train,X_test,y_test):\n",
    "    # LogisticRegression\n",
    "    alg = \"Logistic Regression\" \n",
    "    ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "    startTime = time.time()\n",
    "    ovr.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime\n",
    "    y_predict =ovr.predict(X_test) \n",
    "    info = {\"solver\":\"lbfgs\"}\n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "    \n",
    "    # Neural Network Classifier \n",
    "    alg = \"Neural Network Classifier\" \n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "    startTime = time.time()\n",
    "    mlp_clf.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =mlp_clf.predict(X_test)   \n",
    "    info = { \"activation\" : 'logistic', \"solver\" : 'adam'}\n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "    \n",
    "\n",
    "    # Gaussian Naive Bayes\n",
    "    alg = \"Naive Bayes\"\n",
    "    gnb = GaussianNB()\n",
    "    startTime = time.time()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =gnb.predict(X_test) \n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n",
    "\n",
    "    # Decision Tree\n",
    "    alg = \"Decision Tree\"\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    startTime = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict =clf.predict(X_test) \n",
    "    calculateAcc(y_test,y_predict,dataSetName, alg,info,0, executionTime)\n",
    "    pickle.dump(ovr, open(\"models/\" + dataSetName + \"_\" + alg + \".h5\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Logistic Regression 0.9666666666666667\n",
      "IRIS Neural Network Classifier 0.9666666666666667\n",
      "IRIS Naive Bayes 1.0\n",
      "IRIS Decision Tree 1.0\n"
     ]
    }
   ],
   "source": [
    "dataSetName = \"IRIS\"\n",
    "iris = datasets.load_iris()  \n",
    "X = iris.data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X)  \n",
    "pickle.dump(scaler, open( \"models/scaling_\" + dataSetName + \".pkl\" , 'wb'))\n",
    "X = scaler.transform(X)\n",
    "y = iris.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "modelingPipeline( dataSetName, X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits Logistic Regression 0.9666666666666667\n",
      "Digits Neural Network Classifier 0.9111111111111111\n",
      "Digits Naive Bayes 0.7666666666666667\n",
      "Digits Decision Tree 0.8638888888888889\n"
     ]
    }
   ],
   "source": [
    "dataSetName = \"Digits\"\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X)   \n",
    "pickle.dump(scaler, open( \"models/scaling_\" + dataSetName + \".pkl\" , 'wb'))\n",
    "X = scaler.transform(X)\n",
    "y = digits.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "modelingPipeline( dataSetName, X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21826404a90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetName = \"IRIS\"\n",
    "iris = datasets.load_iris()  \n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(X[:,3].max())\n",
    "print(X[:,3].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max values in features before scaling :  255.0\n",
      "the min values in features before scaling :  0.0\n"
     ]
    }
   ],
   "source": [
    "# normalizing features \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(features_raw) \n",
    "print(\"the max values in features before scaling : \",features_raw.max().max()) \n",
    "print(\"the min values in features before scaling : \",features_raw.min().min()) \n",
    "features = scaler.transform(features_raw) # transform the features to StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (56000, 784)\n",
      "X_test:  (14000, 784)\n",
      "y_train:  (56000,)\n",
      "y_test:  (14000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=0.2, random_state=42) \n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape) \n",
    "print(\"y_test: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset originally had 784 features (columns). We aimed to reduce this number using Principal Component Analysis (PCA) while retaining most of the information. We started by keeping the top 50 principal components, which captured 43% of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000, 50)\n",
      "(14000, 784) (14000, 50)\n",
      "0.4373978939213167\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "print(X_train.shape, X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_test.shape, X_test_pca.shape)\n",
    "\n",
    "print(pca.noise_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Explore the variance explained by the selected number\n",
    "#  of components and adjust if necessary to retain at least\n",
    "# 95% of the variance.\n",
    "n_componentsExplore = []\n",
    "for n_components in range(5,784,25): \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    noise_variance = pca.noise_variance_\n",
    "    n_componentsExplore.append([n_components,noise_variance]) \n",
    "    if(noise_variance < 0.05):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 0.7461170433292454],\n",
       " [30, 0.5208512615736208],\n",
       " [55, 0.4206365826195105],\n",
       " [80, 0.35148862085679317],\n",
       " [105, 0.29616477290608867],\n",
       " [130, 0.2518414187031177],\n",
       " [155, 0.21298846723225007],\n",
       " [180, 0.1804277796982072],\n",
       " [205, 0.15407449695463218],\n",
       " [230, 0.13215853799050223],\n",
       " [255, 0.11467577530595356],\n",
       " [280, 0.10024391623636372],\n",
       " [305, 0.08809805927432372],\n",
       " [330, 0.07777820168987501],\n",
       " [355, 0.06912136440487493],\n",
       " [380, 0.06167311242764846],\n",
       " [405, 0.055253201130123566],\n",
       " [430, 0.04947378672653263]]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_componentsExplore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal number of components for our analysis, the below loop that iteratively increased the number of components by 25, all the way up to 784. The loop stopped when the explained variance reached 95%. This process is visualized in a scree plot, which helps us see how adding more components contributes to the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scree plot to find the elbo at 0.05\n",
    "n_componentsExploreArr = np.zeros([len(n_componentsExplore),2])\n",
    "for i in n_componentsExplore: \n",
    "    n_componentsExploreArr = np.append(n_componentsExploreArr,[i] , axis=0)\n",
    "    \n",
    "plt.style.use('_mpl-gallery') \n",
    "x = np.matrix(n_componentsExplore)[:,0]\n",
    "y = np.matrix(n_componentsExplore)[:,1] \n",
    "fig, ax = plt.subplots()\n",
    "plt.axhline(y = 0.05, color = 'r', linestyle = 'dashed')    \n",
    "ax.plot(x, y, linewidth=2.0) \n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an alternative method provided by scikit-learn. This method allows us to specify the desired explained variance, and scikit-learn will find the closest number of components that achieves that level of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07801665582474857\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "# alternative method: \n",
    "pca = PCA(n_components= 0.95, svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "print(pca.noise_variance_)\n",
    "print(len(pca.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000, 400)\n",
      "(14000, 784) (14000, 400)\n",
      "0.05645825103308629\n"
     ]
    }
   ],
   "source": [
    "# For this particular task, I chose to use 400 components \n",
    "n_components = 400\n",
    "pca = PCA(n_components= n_components)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# transforming x train and x test\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_train_pca.shape)\n",
    "print(X_test.shape, X_test_pca.shape)\n",
    "print(pca.noise_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultsSummary = pd.DataFrame([])\n",
    "def calculateAcc(y_test,y_predict,methodName1,methodNam2,executionTime,df_resultsSummary, printResults = True): \n",
    "    conf_matrix = confusion_matrix(y_test, y_predict ) \n",
    "    if(printResults):\n",
    "        print(conf_matrix) \n",
    "        print(classification_report(y_test, y_predict ))\n",
    "    acc_ovr = accuracy_score(y_test, y_predict)\n",
    "    return pd.concat([df_resultsSummary,pd.DataFrame([[methodName1,methodNam2,acc_ovr,executionTime]]\n",
    "                                                     ,columns=[\"Model\",\"Data\",\"accuracy\",\"executionTime\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1305    1    5    0    1    6   14    2    8    1]\n",
      " [   0 1557    5    8    2   10    1    3   13    1]\n",
      " [   8   16 1233   23   16   13   18   15   31    7]\n",
      " [   7   11   34 1269    1   38    7   18   25   23]\n",
      " [   4    2    9    6 1200    3    7    7   13   44]\n",
      " [   8   10    7   50   14 1112   21    7   34   10]\n",
      " [   4    5   16    1   11   23 1330    0    6    0]\n",
      " [   6    4   21    3   14    7    0 1409    5   34]\n",
      " [  14   37   17   44    9   45   14   10 1138   29]\n",
      " [   8    9    6   23   46    9    0   52   11 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1343\n",
      "           1       0.94      0.97      0.96      1600\n",
      "           2       0.91      0.89      0.90      1380\n",
      "           3       0.89      0.89      0.89      1433\n",
      "           4       0.91      0.93      0.92      1295\n",
      "           5       0.88      0.87      0.88      1273\n",
      "           6       0.94      0.95      0.95      1396\n",
      "           7       0.93      0.94      0.93      1503\n",
      "           8       0.89      0.84      0.86      1357\n",
      "           9       0.89      0.88      0.89      1420\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement a Logistic Regression classifier.\n",
    "ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "# Train One-Vs-Rest Logistic Regression\n",
    "startTime = time.time()\n",
    "ovr.fit(X_train, y_train)\n",
    "executionTime = time.time()-startTime\n",
    "# predict lbfgs PCA\n",
    "y_predict =ovr.predict(X_test)  \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"Logistic Regression\",\n",
    "                                 \"all Features - no PCA\", executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1304    1    4    1    2    8   11    2    8    2]\n",
      " [   0 1557    4    9    2    9    3    4   11    1]\n",
      " [   6   18 1239   17   15   10   19   15   34    7]\n",
      " [   8    9   37 1268    2   41    6   19   25   18]\n",
      " [   3    2    8    7 1201    3    6    8   12   45]\n",
      " [   7    8    6   50   16 1113   23    5   35   10]\n",
      " [   6    4   16    1   10   19 1335    0    5    0]\n",
      " [   5    4   21    0   11    7    0 1421    2   32]\n",
      " [  10   36   15   40    9   44   12   12 1154   25]\n",
      " [  10   10    6   22   45    9    0   52   13 1253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1343\n",
      "           1       0.94      0.97      0.96      1600\n",
      "           2       0.91      0.90      0.91      1380\n",
      "           3       0.90      0.88      0.89      1433\n",
      "           4       0.91      0.93      0.92      1295\n",
      "           5       0.88      0.87      0.88      1273\n",
      "           6       0.94      0.96      0.95      1396\n",
      "           7       0.92      0.95      0.93      1503\n",
      "           8       0.89      0.85      0.87      1357\n",
      "           9       0.90      0.88      0.89      1420\n",
      "\n",
      "    accuracy                           0.92     14000\n",
      "   macro avg       0.92      0.92      0.92     14000\n",
      "weighted avg       0.92      0.92      0.92     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr = LogisticRegression(random_state=15, multi_class='ovr', solver='lbfgs')\n",
    "# Train One-Vs-Rest Logistic Regression\n",
    "startTime = time.time()\n",
    "ovr.fit(X_train_pca, y_train)\n",
    "executionTime = time.time()-startTime\n",
    "# predict lbfgs PCA\n",
    "y_predict =ovr.predict(X_test_pca)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"Logistic Regression\",\n",
    "                                 \"PCA (400 components)\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1252    0   11    1    9   19   29    2   11    9]\n",
      " [   0 1531   11   12    1    8    1    7   28    1]\n",
      " [  27   28 1224   34   10    3   15   13   23    3]\n",
      " [   7   14   30 1268    2   46    3   25   18   20]\n",
      " [   8    1    9    0 1183    7   22   14   11   40]\n",
      " [   6    7    8   54    7 1096   10   10   52   23]\n",
      " [  16    4   20    0   22   15 1302    3   13    1]\n",
      " [   3   12   17   23   18   17    2 1348    2   61]\n",
      " [  13   24   33   28    4   61   16    8 1144   26]\n",
      " [  13    2    3   10   62   16    3   61   13 1237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1343\n",
      "           1       0.94      0.96      0.95      1600\n",
      "           2       0.90      0.89      0.89      1380\n",
      "           3       0.89      0.88      0.89      1433\n",
      "           4       0.90      0.91      0.91      1295\n",
      "           5       0.85      0.86      0.86      1273\n",
      "           6       0.93      0.93      0.93      1396\n",
      "           7       0.90      0.90      0.90      1503\n",
      "           8       0.87      0.84      0.86      1357\n",
      "           9       0.87      0.87      0.87      1420\n",
      "\n",
      "    accuracy                           0.90     14000\n",
      "   macro avg       0.90      0.90      0.90     14000\n",
      "weighted avg       0.90      0.90      0.90     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part IV: Neural Network Classifier \n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "startTime = time.time()\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "executionTime = time.time()-startTime \n",
    "y_predict =mlp_clf.predict(X_test)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"NN Classifier, 3 layers, logistic\",\n",
    "                                \"All Features - no PCA\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1252    2   15    1    0   29   32    3    9    0]\n",
      " [   1 1548    8   10    2    3    1   10   13    4]\n",
      " [  27   14 1229   25   10    9   12   17   31    6]\n",
      " [   0    5   31 1275    2   57    0   23   26   14]\n",
      " [   2    5    3    1 1186   11   20    6    7   54]\n",
      " [   8    4    3   59    7 1122   12    6   43    9]\n",
      " [  31    3   13    0   22   14 1304    0    7    2]\n",
      " [   8   12   11   31    7    8    1 1376    2   47]\n",
      " [   8   21   18   28    6   34   20    5 1201   16]\n",
      " [   4    4    6   12   55   16    3   34   11 1275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1343\n",
      "           1       0.96      0.97      0.96      1600\n",
      "           2       0.92      0.89      0.90      1380\n",
      "           3       0.88      0.89      0.89      1433\n",
      "           4       0.91      0.92      0.92      1295\n",
      "           5       0.86      0.88      0.87      1273\n",
      "           6       0.93      0.93      0.93      1396\n",
      "           7       0.93      0.92      0.92      1503\n",
      "           8       0.89      0.89      0.89      1357\n",
      "           9       0.89      0.90      0.90      1420\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 1000, activation = 'logistic', solver = 'adam')\n",
    "startTime = time.time()\n",
    "mlp_clf.fit(X_train_pca, y_train)\n",
    "executionTime = time.time()-startTime \n",
    "y_predict = mlp_clf.predict(X_test_pca)   \n",
    "df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                 \"NN Classifier, 3 layers, logistic\",\n",
    "                                 \"PCA (400 components)\",\n",
    "                                 executionTime,\n",
    "                                 df_resultsSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Options [['adam', 'logistic', 'constant', 'All Features - no PCA'], ['adam', 'logistic', 'constant', 'PCA (400 components)'], ['adam', 'logistic', 'adaptive', 'All Features - no PCA'], ['adam', 'logistic', 'adaptive', 'PCA (400 components)'], ['adam', 'relu', 'constant', 'All Features - no PCA'], ['adam', 'relu', 'constant', 'PCA (400 components)'], ['adam', 'relu', 'adaptive', 'All Features - no PCA'], ['adam', 'relu', 'adaptive', 'PCA (400 components)'], ['adam', 'tanh', 'constant', 'All Features - no PCA'], ['adam', 'tanh', 'constant', 'PCA (400 components)'], ['adam', 'tanh', 'adaptive', 'All Features - no PCA'], ['adam', 'tanh', 'adaptive', 'PCA (400 components)'], ['sgd', 'logistic', 'constant', 'All Features - no PCA'], ['sgd', 'logistic', 'constant', 'PCA (400 components)'], ['sgd', 'logistic', 'adaptive', 'All Features - no PCA'], ['sgd', 'logistic', 'adaptive', 'PCA (400 components)'], ['sgd', 'relu', 'constant', 'All Features - no PCA'], ['sgd', 'relu', 'constant', 'PCA (400 components)'], ['sgd', 'relu', 'adaptive', 'All Features - no PCA'], ['sgd', 'relu', 'adaptive', 'PCA (400 components)'], ['sgd', 'tanh', 'constant', 'All Features - no PCA'], ['sgd', 'tanh', 'constant', 'PCA (400 components)'], ['sgd', 'tanh', 'adaptive', 'All Features - no PCA'], ['sgd', 'tanh', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'logistic', 'constant', 'All Features - no PCA'], ['lbfgs', 'logistic', 'constant', 'PCA (400 components)'], ['lbfgs', 'logistic', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'logistic', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'relu', 'constant', 'All Features - no PCA'], ['lbfgs', 'relu', 'constant', 'PCA (400 components)'], ['lbfgs', 'relu', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'relu', 'adaptive', 'PCA (400 components)'], ['lbfgs', 'tanh', 'constant', 'All Features - no PCA'], ['lbfgs', 'tanh', 'constant', 'PCA (400 components)'], ['lbfgs', 'tanh', 'adaptive', 'All Features - no PCA'], ['lbfgs', 'tanh', 'adaptive', 'PCA (400 components)']]\n",
      "['sgd', 'tanh', 'adaptive', 'All Features - no PCA']\n",
      "['sgd', 'relu', 'constant', 'PCA (400 components)']\n",
      "['sgd', 'tanh', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'logistic', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'relu', 'adaptive', 'PCA (400 components)']\n",
      "['adam', 'relu', 'constant', 'PCA (400 components)']\n",
      "['lbfgs', 'logistic', 'constant', 'All Features - no PCA']\n",
      "['adam', 'relu', 'adaptive', 'PCA (400 components)']\n",
      "['adam', 'tanh', 'constant', 'All Features - no PCA']\n",
      "['sgd', 'tanh', 'constant', 'All Features - no PCA']\n"
     ]
    }
   ],
   "source": [
    "# Define the grid search space\n",
    "optimizers = ['adam', 'sgd','lbfgs']\n",
    "activations = ['logistic','relu', 'tanh']  \n",
    "learning_rate = ['constant', 'adaptive']\n",
    "dataSource = ['All Features - no PCA','PCA (400 components)']\n",
    "\n",
    "options = [] # define empty list \n",
    "for optimizer, activation,learning_rate,dataSource in product(optimizers, activations,learning_rate,dataSource):\n",
    "  options.append([optimizer,activation,learning_rate,dataSource]) # add all possible options \n",
    "\n",
    "searchingOptions = np.random.choice(len(options),10, replace=False) # randomly pick 10 options \n",
    "print(\"All Options\", options) \n",
    "for i in searchingOptions:\n",
    "  print(options[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sgd', 'tanh', 'adaptive', 'All Features - no PCA']  accuracy: 0.9167857142857143\n",
      "['sgd', 'relu', 'constant', 'PCA (400 components)']  accuracy: 0.9393571428571429\n",
      "['sgd', 'tanh', 'constant', 'PCA (400 components)']  accuracy: 0.927\n",
      "['lbfgs', 'logistic', 'constant', 'PCA (400 components)']  accuracy: 0.9050714285714285\n",
      "['lbfgs', 'relu', 'adaptive', 'PCA (400 components)']  accuracy: 0.9363571428571429\n",
      "['adam', 'relu', 'constant', 'PCA (400 components)']  accuracy: 0.9352857142857143\n",
      "['lbfgs', 'logistic', 'constant', 'All Features - no PCA']  accuracy: 0.9005\n",
      "['adam', 'relu', 'adaptive', 'PCA (400 components)']  accuracy: 0.9388571428571428\n",
      "['adam', 'tanh', 'constant', 'All Features - no PCA']  accuracy: 0.9128571428571428\n",
      "['sgd', 'tanh', 'constant', 'All Features - no PCA']  accuracy: 0.9152142857142858\n"
     ]
    }
   ],
   "source": [
    "for i in searchingOptions: \n",
    "    activation = options[i][1] \n",
    "    solver = options[i][0] \n",
    "    learning_rate = options[i][2]\n",
    "    dataSource = options[i][3] \n",
    "    if(dataSource == \"All Features - no PCA\"):\n",
    "        trainingData = X_train\n",
    "        testingData = X_test\n",
    "    else:\n",
    "        trainingData = X_train_pca\n",
    "        testingData = X_test_pca\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(16,12,8), max_iter = 500,\n",
    "                             activation = activation, solver = solver,learning_rate=learning_rate)\n",
    "    startTime = time.time()\n",
    "    mlp_clf.fit(trainingData, y_train)\n",
    "    executionTime = time.time()-startTime \n",
    "    y_predict = mlp_clf.predict(testingData)   \n",
    "    df_resultsSummary = calculateAcc(y_test,y_predict,\n",
    "                                    \"hyperparameters activation\" + activation + \" solver:\" + solver + \" learning_rate\" + learning_rate,\n",
    "                                    dataSource,\n",
    "                                    executionTime,\n",
    "                                    df_resultsSummary,printResults=False)\n",
    "    print(options[i],\" accuracy:\",df_resultsSummary.tail(1)[\"accuracy\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>executionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>25.284516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN Classifier, 3 layers, logistic</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.898929</td>\n",
       "      <td>317.773614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN Classifier, 3 layers, logistic</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>185.229174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.916786</td>\n",
       "      <td>357.610471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:sgd lear...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.939357</td>\n",
       "      <td>228.033520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>216.902335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationlogistic solver:lbfg...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>120.471338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:lbfgs le...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.936357</td>\n",
       "      <td>79.072497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:adam lea...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.935286</td>\n",
       "      <td>109.893801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationlogistic solver:lbfg...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.900500</td>\n",
       "      <td>192.081178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationrelu solver:adam lea...</td>\n",
       "      <td>PCA (400 components)</td>\n",
       "      <td>0.938857</td>\n",
       "      <td>116.923919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:adam lea...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>133.931399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperparameters activationtanh solver:sgd lear...</td>\n",
       "      <td>All Features - no PCA</td>\n",
       "      <td>0.915214</td>\n",
       "      <td>438.949612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model                   Data  \\\n",
       "0                                Logistic Regression   PCA (400 components)   \n",
       "0                  NN Classifier, 3 layers, logistic  All Features - no PCA   \n",
       "0                  NN Classifier, 3 layers, logistic   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:sgd lear...  All Features - no PCA   \n",
       "0  hyperparameters activationrelu solver:sgd lear...   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:sgd lear...   PCA (400 components)   \n",
       "0  hyperparameters activationlogistic solver:lbfg...   PCA (400 components)   \n",
       "0  hyperparameters activationrelu solver:lbfgs le...   PCA (400 components)   \n",
       "0  hyperparameters activationrelu solver:adam lea...   PCA (400 components)   \n",
       "0  hyperparameters activationlogistic solver:lbfg...  All Features - no PCA   \n",
       "0  hyperparameters activationrelu solver:adam lea...   PCA (400 components)   \n",
       "0  hyperparameters activationtanh solver:adam lea...  All Features - no PCA   \n",
       "0  hyperparameters activationtanh solver:sgd lear...  All Features - no PCA   \n",
       "\n",
       "   accuracy  executionTime  \n",
       "0  0.917500      25.284516  \n",
       "0  0.898929     317.773614  \n",
       "0  0.912000     185.229174  \n",
       "0  0.916786     357.610471  \n",
       "0  0.939357     228.033520  \n",
       "0  0.927000     216.902335  \n",
       "0  0.905071     120.471338  \n",
       "0  0.936357      79.072497  \n",
       "0  0.935286     109.893801  \n",
       "0  0.900500     192.081178  \n",
       "0  0.938857     116.923919  \n",
       "0  0.912857     133.931399  \n",
       "0  0.915214     438.949612  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultsSummary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
